{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "from keras.optimizers import RMSprop\n",
    "from keras.preprocessing.image import ImageDataGenerator\n",
    "import cv2\n",
    "import tensorflow\n",
    "from keras.models import Sequential\n",
    "from keras.layers import Conv2D, Input, ZeroPadding2D, BatchNormalization, Activation, MaxPooling2D, Flatten, Dense, Dropout\n",
    "from keras.models import Model, load_model\n",
    "from keras.callbacks import TensorBoard, ModelCheckpoint\n",
    "from sklearn.model_selection import train_test_split\n",
    "from sklearn.metrics import f1_score\n",
    "from sklearn.utils import shuffle\n",
    "import imutils\n",
    "import numpy as np\n",
    "import pandas as pd\n",
    "import matplotlib.pyplot as plt"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Build a Neural Network\n",
    "This convolution network consists of two pairs of Conv and MaxPool layers to extract features from the dataset. Which is then followed by a Flatten and Dropout layer to convert the data in 1D and ensure overfitting.\n",
    "\n",
    "And then two Dense layers for classification."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "model = Sequential([\n",
    "    Conv2D(100, (3,3), activation = 'relu', input_shape = (150,150,3)),\n",
    "    MaxPooling2D(2,2),\n",
    "    \n",
    "    Conv2D(100, (3,3), activation = 'relu'),\n",
    "    MaxPooling2D(2,2),\n",
    "    \n",
    "    Flatten(),\n",
    "    Dropout(0.5),\n",
    "    Dense(50, activation = 'relu'),\n",
    "    Dense(2, activation = 'softmax')\n",
    "])\n",
    "model.compile(loss=tensorflow.keras.losses.categorical_crossentropy,\n",
    "              optimizer=tensorflow.keras.optimizers.Adam(),\n",
    "              metrics=['acc'])"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#  Image Data Generation/Augmentation"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Found 1275 images belonging to 2 classes.\n",
      "Found 194 images belonging to 2 classes.\n"
     ]
    }
   ],
   "source": [
    "## ImageDataGenerator class => Generate batches of tensor image data with real-time data augmentation.\n",
    "## Rescale 1./255 is to transform every pixel value from range [0,255] -> [0,1]. And the benefits are: \n",
    "# Treat all images in the same manner: some images are high pixel range, some are low pixel range.\n",
    "\n",
    "train_dir = \"C:\\\\Users\\\\gkhat\\\\Desktop\\\\Dataset\\\\train\"\n",
    "train_datagen = ImageDataGenerator (rescale = 1.0/255,\n",
    "                                   rotation_range = 40,\n",
    "                                   width_shift_range = 0.2,\n",
    "                                   shear_range = 0.2,\n",
    "                                   zoom_range = 0.2,\n",
    "                                   horizontal_flip = True,\n",
    "                                   fill_mode = 'nearest')\n",
    "\n",
    "train_generator = train_datagen.flow_from_directory(train_dir,\n",
    "                                                    batch_size = 10,\n",
    "                                                    target_size = (150,150))\n",
    "\n",
    "validation_dir = \"C:\\\\Users\\\\gkhat\\\\Desktop\\\\Dataset\\\\test\"\n",
    "validation_datagen = ImageDataGenerator(rescale = 1.0/255)\n",
    "\n",
    "validation_generator = validation_datagen.flow_from_directory(validation_dir,\n",
    "                                                              batch_size = 10,\n",
    "                                                              target_size = (150,150))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Initialize a callback checkpoint to keep saving best model after each epoch while training"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "checkpoint = ModelCheckpoint('model12-{epoch:03d}.model',\n",
    "                            monitor = 'val_loss',\n",
    "                            verbose = 0,\n",
    "                            save_best_only = True,\n",
    "                            mode = 'auto')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Train the model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "** Path: C:\\Users\\gkhat\\Desktop\\Dataset\\train\\with_mask\\portrait-doctor-with-surgical-mask-stethoscope-23-2148454273.jpg  *****\r"
     ]
    }
   ],
   "source": [
    "import os\n",
    "from PIL import Image\n",
    "folder_path = r'C:\\Users\\gkhat\\Desktop\\Dataset\\train'\n",
    "extensions = []\n",
    "for fldr in os.listdir(folder_path):\n",
    "    sub_folder_path = os.path.join(folder_path, fldr)\n",
    "    for filee in os.listdir(sub_folder_path):\n",
    "        file_path = os.path.join(sub_folder_path, filee)\n",
    "        print('** Path: {}  **'.format(file_path), end=\"\\r\", flush=True)\n",
    "        im = Image.open(file_path)\n",
    "        rgb_im = im.convert('RGB')\n",
    "        if filee.split('.')[1] not in extensions:\n",
    "            extensions.append(filee.split('.')[1])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 1/10\n",
      "128/128 [==============================] - ETA: 0s - loss: 0.6179 - acc: 0.7271WARNING:tensorflow:From C:\\Users\\gkhat\\anaconda3\\lib\\site-packages\\tensorflow\\python\\training\\tracking\\tracking.py:111: Model.state_updates (from tensorflow.python.keras.engine.training) is deprecated and will be removed in a future version.\n",
      "Instructions for updating:\n",
      "This property should not be used in TensorFlow 2.0, as updates are applied automatically.\n",
      "WARNING:tensorflow:From C:\\Users\\gkhat\\anaconda3\\lib\\site-packages\\tensorflow\\python\\training\\tracking\\tracking.py:111: Layer.updates (from tensorflow.python.keras.engine.base_layer) is deprecated and will be removed in a future version.\n",
      "Instructions for updating:\n",
      "This property should not be used in TensorFlow 2.0, as updates are applied automatically.\n",
      "INFO:tensorflow:Assets written to: model12-001.model\\assets\n",
      "128/128 [==============================] - 108s 844ms/step - loss: 0.6179 - acc: 0.7271 - val_loss: 0.2728 - val_acc: 0.9278\n",
      "Epoch 2/10\n",
      "128/128 [==============================] - ETA: 0s - loss: 0.2749 - acc: 0.9035INFO:tensorflow:Assets written to: model12-002.model\\assets\n",
      "128/128 [==============================] - 119s 929ms/step - loss: 0.2749 - acc: 0.9035 - val_loss: 0.1181 - val_acc: 0.9536\n",
      "Epoch 3/10\n",
      "128/128 [==============================] - ETA: 0s - loss: 0.1843 - acc: 0.9396INFO:tensorflow:Assets written to: model12-003.model\\assets\n",
      "128/128 [==============================] - 117s 916ms/step - loss: 0.1843 - acc: 0.9396 - val_loss: 0.0910 - val_acc: 0.9588\n",
      "Epoch 4/10\n",
      "128/128 [==============================] - 105s 818ms/step - loss: 0.2370 - acc: 0.9153 - val_loss: 0.1643 - val_acc: 0.9536\n",
      "Epoch 5/10\n",
      "128/128 [==============================] - 106s 828ms/step - loss: 0.2416 - acc: 0.9325 - val_loss: 0.1284 - val_acc: 0.9536\n",
      "Epoch 6/10\n",
      "128/128 [==============================] - 103s 808ms/step - loss: 0.2081 - acc: 0.9294 - val_loss: 0.1156 - val_acc: 0.9485\n",
      "Epoch 7/10\n",
      "128/128 [==============================] - 104s 815ms/step - loss: 0.2131 - acc: 0.9318 - val_loss: 0.1516 - val_acc: 0.9433\n",
      "Epoch 8/10\n",
      "128/128 [==============================] - 103s 807ms/step - loss: 0.1851 - acc: 0.9318 - val_loss: 0.1529 - val_acc: 0.9330\n",
      "Epoch 9/10\n",
      "128/128 [==============================] - 103s 807ms/step - loss: 0.1511 - acc: 0.9420 - val_loss: 0.1239 - val_acc: 0.9588\n",
      "Epoch 10/10\n",
      "128/128 [==============================] - 107s 838ms/step - loss: 0.1470 - acc: 0.9467 - val_loss: 0.1131 - val_acc: 0.9588\n"
     ]
    }
   ],
   "source": [
    "train = model.fit(train_generator,\n",
    "                           epochs = 10,\n",
    "                           validation_data = validation_generator,\n",
    "                           callbacks = [checkpoint])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.3"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
